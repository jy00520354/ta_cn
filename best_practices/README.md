!!! 注意：这只是一个试验性的演示，并不一定达到了最佳

# 说明
本演示经历了两个阶段
1. 多文件多进程并行计算。没有找到合适的多进程计算库，所以前期用的此方案。缺点是计算前需要合并数据，占用大量资源
2. 使用支持多线程的库

不同于普通的机器学习任务，可以直接使用sklearn等库进行数据处理。金融机器学习任务有特殊性，需要分日期（横截面）、分股票（时序）进行处理。
所以对于groupby和apply有要求。
1. apply最好支持调用numpy、talib、numba等函数
2. groupby最好支持多线程，否则只能通过切文件后多进程处理。

# 可能的加速方案
Python无法直接利用多核进行加速。如何加速计算，可能方案有：
1. 调用C++、Rust等一类的库，这些库底层实现多线程计算。
    - 一般无法直接利用pandas、talib等库的函数，学习难度大，开发工作量更大
2. 多进程处理，实际上数据会被序列化到硬盘再反序列化到每个进程，数据大时极为耗时。
    - 如果能砍掉序列化这个步骤，每个进程只反序列化自己部分，这样速度能快不少。
    - 但只反序列化自己部分需要建立索引，否则无法找到指定位置
    - 单个文件内部的索引相当于要设计一种全新的文件格式，过于复杂，不考虑
    - 最终，多个文件实现起来更简单
3. 如果到Python 3.12版本以后，GIL真的取消掉可以真的实现多线程，那么这种分文件的方式也就没有必要了。
只要提前分配好对应内存，后面就分区计算即可
    
## 多文件方案
1. 数据使用长表进行保存。方便从末尾添加数据，节约存储空间，容易添加新股票，方便机器学习，但计算指标速度慢。
2. 同一属性的数据有二维：时间（行）、合约（列）。
3. 二维数据可以按九宫格方式分割成多块。每格，文件标记成 `行__列`。目前行按年划分，而列按股票最后一个数字分成10组。如果数据量大，可以分得更细
4. 当要做时序计算时将同列的数据纵向合并成长表，如 `*__列` 为长时序数据。然后按`股票`分组后计算`时序指标`
5. 当要做截面计算时将同行的数据横向合并成长表，如 `行__*` 为横截面数据。然后按`时间`分组后计算`截面指标`
6. 时序计算，根据指标的特性，有可能只使用一段数据即可计算正确或近似。而横截面计算可能整行都得参与计算才正确
7. 每个块由输入、计算、输出三个功能组成。需根据计算要求，设计输入是整行(时序)加载还是整列(截面)加载
8. 默认每个块的输出数据与输入同形式，同为整行或整列。如果下一块形式不同，则当前块要输出九宫格式来适应下一块。
    - 原数据`田`划分，由于第一块计算时序指标，所以指定按`川`读入，2个进程
    - 第二块计算截面指标，将`川`整行读入，会导致1进程数据全加载。
    - 所以第一块的输出必须还原成`田`，第二块就能按`三`读入，2个进程
9. 一般不再需要跳过空值的调整，也不需要二维函数了。因为长表在stack时默认就丢弃了空值，所以直接算即可
    
## 进一步优化
1. 输入时的多文件加载合并，输出时的分组写入。这些都是瓶颈。
2. 硬盘换成固态硬盘。或加大内存，数据写入共享内存中。
3. 进程数多不一定能提高速度，因为可能IO瓶颈，硬盘忙不过来。
4. 进程过多还有可能导至内存占用过高，进而导致内存不足而崩溃
6. 每次时序或截面计算时都要考虑减少内存

## 结论
1. 三年4000多支股票，日线数据，计算十几个指标。numba启用缓存
2. 3进程初始准备，5进程时序指标，3进程截面指标。用时约80秒
2. 1进程初始准备，1进程时序指标，1进程截面指标。用时约250秒

## 宽表版
1. 此处长表版与ta_cn长表版区别是groupby时机问题。
    - ta_cn版每个公式函数都要groupby，几十个指标就需要groupby几十次
    - 而这里不管有多少公式，只groupby一次
2. 缺点是没有ta_cn长表版易用，比如想先横截面排序，然后时序相关系数，工序比较多
3. 宽表版，需要将数据全都整理成宽表，然后每个宽表需要一层文件，所以需要另行设计文件路径
    - `行__列`已经用了，可以一个文件夹为字段名，内再放parquet文件
    - 考虑以后再测试此功能

# 多线程方案
考察了polars和vaex后，最后选择的polars
1. polars: 语法需要重新学习
2. vaex: 函数与pandas比较接近。但apply时可能是多进程并出现复制

## 进一步优化
1. 结果相同的情况下，优先使用polars提供的函数
2. 加内存条，或者使用mmap模式等